#!/usr/bin/env python3

import time
import prometheus_client
from prometheus_client.core import GaugeMetricFamily
import datetime
import asyncio
import aiohttp
import pyotp
import pyjson5
import os
import traceback

config = None
session = None
login_headers = {
    "User-Agent": 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    "Referer": "https://www.coned.com/",
    "authorization": '',
}

# Records electricity usage data for graphing in prometheus
def main():
    registry = setup_prometheus()
    with open(os.path.abspath(os.path.dirname(__file__) + '/..') + '/config.json') as config_json:
        global config
        config = pyjson5.decode(config_json.read())['electricity_credentials']
    while True:
        # Scrape once every 5m. Electricity usage data comes in 15m increments, and it is ~1 hr delayed.
        time.sleep(300)
        prometheus_client.write_to_textfile('/home/pi/observability/timestamped_textfile_collector_data/electricity_data.prom', registry)

# Save disk space by not collecting unneeded stats.
def setup_prometheus():
    # https://github.com/prometheus/client_python#disabling-default-collector-metrics
    prometheus_client.REGISTRY.unregister(prometheus_client.GC_COLLECTOR)
    prometheus_client.REGISTRY.unregister(prometheus_client.PLATFORM_COLLECTOR)
    prometheus_client.REGISTRY.unregister(prometheus_client.PROCESS_COLLECTOR)

    registry = prometheus_client.CollectorRegistry()
    registry.register(CustomTimestampedGaugeCollector())
    return registry

async def get_realtime_usage_data():
    global session
    session = aiohttp.ClientSession()
    try:
        return await internal_get_realtime_usage_data()
    except Exception as e:
        raise e
    finally:
        await session.close()

# Influenced heavily by this example:
# https://github.com/tronikos/opower/blob/main/src/opower/utilities/coned.py
#
# See also this, which relies on web scraping:
# https://github.com/bvlaicu/coned/blob/master/coned/meter.py
#
# See also my earlier implementation, which relied on web scraping:
# https://github.com/dasl-/pitools/blob/e66a6ededab5272c3d24c40d9a523385466ec8ef/sensors/measure_electricity_usage
async def internal_get_realtime_usage_data():
    global login_headers
    # Double-logins are somewhat broken if cookies stay around.
    # Let's clear everything except device tokens (which allow skipping 2FA)
    session.cookie_jar.clear(
        lambda cookie: cookie["domain"] == "www.coned.com"
        and cookie.key != "CE_DEVICE_ID"
    )
    login_url = 'https://www.coned.com/sitecore/api/ssc/ConEdWeb-Foundation-Login-Areas-LoginAPI/User/0/Login'
    post_data = {
        "LoginEmail": config['email'],
        "LoginPassword": config['password'],
        "LoginRememberMe": False,
        "ReturnUrl": '/en/accounts-billing/my-account/energy-use',
        "OpenIdRelayState": "",
    }
    response = await post_response(login_url, post_data)
    if not response["login"]:
        raise Exception("Unable to login with given credentials - falsey 'login' field in response")

    redirect_url = None
    if "authRedirectUrl" in response:
        redirect_url = response["authRedirectUrl"]
    else:
        if not response["newDevice"]:
            raise Exception("Unable to login with given credentials - falsey 'newDevice' field in response")
        if not response["noMfa"]:
            mfa_code = pyotp.TOTP(config['totp_secret']).now()
            mfa_url = "https://www.coned.com/sitecore/api/ssc/ConEdWeb-Foundation-Login-Areas-LoginAPI/User/0/VerifyFactor"
            json_data = {
                "MFACode": mfa_code,
                "ReturnUrl": "/en/accounts-billing/my-account/energy-use",
                "OpenIdRelayState": "",
            }
            mfa_response = await post_response(mfa_url, json = json_data)
            if not mfa_response["code"]:
                raise Exception("2FA login step failed")
            redirect_url = mfa_response["authRedirectUrl"]

    await get_response(redirect_url, as_json = False)

    power_token_url = "https://www.coned.com/sitecore/api/ssc/ConEd-Cms-Services-Controllers-Opower/OpowerService/0/GetOPowerToken"
    authorization_token = await get_response(power_token_url)
    login_headers['authorization'] = 'Bearer ' + authorization_token

    customer_uuid_url = 'https://cned.opower.com/ei/edge/apis/multi-account-v1/cws/cned/customers/current'
    customer_info = await get_response(customer_uuid_url)
    customer_uuid = customer_info['utilityAccounts'][0]['uuid']

    # Another URL is returns account info also. Not sure which is better to use. See:
    # https://github.com/tronikos/opower/blob/79ca62203932c065b9d282184ea6f9df6d32128f/src/opower/opower.py#L364
    account_url = f'https://cned.opower.com/ei/edge/apis/cws-real-time-ami-v1/cws/cned/accounts/{customer_uuid}/meters'
    account_info = await get_response(account_url)
    account_id = account_info['meters_ids'][0]

    realtime_usage_url = f'https://cned.opower.com/ei/edge/apis/cws-real-time-ami-v1/cws/cned/accounts/{customer_uuid}/meters/{account_id}/usage'
    realtime_usage = await get_response(realtime_usage_url)
    realtime_usage = realtime_usage['reads']

    return format_realtime_usage(realtime_usage)

# input: something that looks like this: https://gist.github.com/dasl-/4c6da56ecc9e6ee1cf89f7a05dd45cb2
def format_realtime_usage(realtime_usage):
    readings = list(filter(lambda read: read['value'] is not None, realtime_usage))

    # Readings are taken every 15m. Get the last 24 hours of readings, in case con ed's website
    # had an extended outage and we have to  catch up. It appears that the API only provides the last
    # 24 hours of readings anyway.
    latest_readings = readings[-96:]
    formatted_readings = []

    for read in latest_readings:
        dt = datetime.datetime.fromisoformat(read['startTime'])
        unix_time_ms = int(round(dt.timestamp()))
        if not unix_time_ms:
            raise Exception('Unable to parse timestamp from response')
        formatted_readings.append((float(read['value']), unix_time_ms))

    return formatted_readings

async def post_response(url, data = None, json = None, timeout = 10, as_json = True):
    async with session.post(
        url,
        data = data,
        json = json,
        headers = login_headers,
        allow_redirects=True,
        timeout = 10
    ) as response:
        if response.status != 200:
            raise Exception(f'Got unexpected status code {response.status} for url: {url}')
        if as_json:
            return await response.json()
        else:
            return await response.text()

async def get_response(url, timeout = 10, as_json = True):
    async with session.get(
        url,
        headers = login_headers,
        allow_redirects=True,
        timeout = timeout
    ) as response:
        if response.status != 200:
            raise Exception(f'Got unexpected status code {response.status} for url: {url}')
        if as_json:
            return await response.json()
        else:
            return await response.text()

# Realtime electricity usage is delayed ~1 hour. The delayed data has a timestamp associated with it.
# Let's pass the timestamp associated with the delayed data point to prometheus
# so that prometheus may associates the data point with the proper time.
#
# https://prometheus.github.io/client_python/collector/custom/
# https://github.com/dasl-/pitools/blob/main/observability/README.adoc#timestamped_exporter
class CustomTimestampedGaugeCollector(prometheus_client.registry.Collector):

    def collect(self):
        try:
            realtime_usage = asyncio.run(get_realtime_usage_data())
        except Exception:
            print(f"Unable to get electricity data: {traceback.format_exc()}", flush = True)
            return []

        gauge_with_custom_timestamp = GaugeMetricFamily(
            'electricity_kwh', 'Electricity usage. Units: KWh.'
        )
        for reading in realtime_usage:
            gauge_with_custom_timestamp.add_metric([], reading[0], reading[1])
        yield gauge_with_custom_timestamp


main()
